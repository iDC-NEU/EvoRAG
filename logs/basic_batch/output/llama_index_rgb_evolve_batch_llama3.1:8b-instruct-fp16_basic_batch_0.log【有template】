/home/zhangyz/miniconda3/envs/llmrag2/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[nltk_data] Downloading package punkt_tab to
[nltk_data]     /home/zhangyz/miniconda3/envs/llmrag2/lib/python3.10/s
[nltk_data]     ite-packages/llama_index/core/_static/nltk_cache...
[nltk_data]   Package punkt_tab is already up-to-date!
/home/zhangyz/miniconda3/envs/llmrag2/lib/python3.10/site-packages/ignite/handlers/checkpoint.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.
  from torch.distributed.optim import ZeroRedundancyOptimizer
WARNING:nebula3.logger:Closing a connection that is in use
Namespace(dataset_name='rgb', llm='llama3.1:8b-instruct-fp16', forward_llm='Meta-Llama-3-8B-Instruct', llm_fb='None', graphdb='nebulagraph', space_name='rgb_zyz', option='evolve_batch', llmbackend='llama_index', iteration=0, type='unchanged', pruning=10, entity=10, hop=2, similar=False, rate=0.0)
{'server': {'ui_port': 8083, 'ui_share': False}, 'llm': {'zhipu': {'url': 'https://open.bigmodel.cn/api/paas/v4', 'key': 'YOUR API-KEY'}, 'moonshot': {'url': 'https://api.moonshot.cn/v1', 'key': 'YOUR API-KEY'}, 'baichuan': {'url': 'https://api.baichuan-ai.com/v1', 'key': 'YOUR API-KEY'}, 'qwen': {'url': 'https://dashscope.aliyuncs.com/compatible-mode/v1', 'key': 'YOUR API-KEY'}, 'lingyiwanwu': {'url': 'https://api.lingyiwanwu.com/v1', 'key': 'YOUR API-KEY'}, 'deepseek': {'url': 'https://api.deepseek.com', 'key': 'YOUR API-KEY'}, 'doubao': {'url': 'https://ark.cn-beijing.volces.com/api/v3', 'key': 'YOUR API-KEY'}, 'gpt': {'url': 'https://api.aigc798.com/v1/', 'key': 'sk-IEnkbBAtmH6L7YuApel4OSTcmdxizcuqpXl4xPTXeaziDA3e'}, 'llama': {'url': 'http://localhost:11434/v1', 'key': 'ollama'}}, 'database': {'neo4j': {'url': 'bolt://localhost:7690', 'username': 'neo4j', 'password': '12345678'}, 'nebulagraph': {'url': '127.0.0.1:9669', 'username': 'root', 'password': 'nebula'}}, 'organization': 'iDC-NE', 'embedding': {'name': 'huggingface', 'model': 'BAAI/bge-large-en-v1.5', 'dim': 1024, 'device': 'cuda:1', 'batch_size': 48}, 'shouldRebuildDatabase': False, 'score_min': 20, 'score_max': 200, 'iteration': 0, 'use_local_model': True, 'entity': 10, 'hop': 2, 'pruning': 10, 'algorithm': 'basic_batch', 'batch_size': 4, 'redundancy': False, 'feedback': True, 'rate': 0.0, 'evolve_basic': {'graphrag_response': 'basic', 'extract_keywords': 'basic', 'retrieve_path': 'basic', 'simThreshold': 0.55, 'score_weight': 0.5, 'scoreThreshold': 70, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'basic_for_triplet', 'top_k_per_entity': True, 'lr': 5000000}, 'evolve_standard': {'graphrag_response': 'basic', 'extract_keywords': 'basic', 'retrieve_path': 'standard', 'simThreshold': 0, 'scoreThreshold': -2, 'score_weight': 0.5, 'lr': 5000000, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'standard_for_path', 'top_k_per_entity': True}, 'evolve_shared_prefix': {'graphrag_response': 'basic_shared_prefix', 'extract_keywords': 'basic', 'retrieve_path': 'standard', 'simThreshold': 0, 'score_weight': 0.5, 'scoreThreshold': -2, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'standard_for_path_shared_prefix', 'top_k_per_entity': True, 'lr': 5000000}, 'standard_batch': {'graphrag_response': 'basic_shared_prefix', 'extract_keywords': 'basic', 'retrieve_path': 'standard', 'simThreshold': 0, 'score_weight': 0.5, 'scoreThreshold': -2, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'standard_for_path_shared_prefix', 'top_k_per_entity': True, 'lr': 5000000}, 'basic_batch': {'graphrag_response': 'basic_shared_prefix', 'extract_keywords': 'basic', 'retrieve_path': 'basic', 'simThreshold': 0, 'score_weight': 0.5, 'scoreThreshold': 61, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'basic_for_triplet_shared_prefix', 'top_k_per_entity': True, 'lr': 5000000}}
{'server': {'ui_port': 8083, 'ui_share': False}, 'llm': 'llama3.1:8b-instruct-fp16', 'database': {'neo4j': {'url': 'bolt://localhost:7690', 'username': 'neo4j', 'password': '12345678'}, 'nebulagraph': {'url': '127.0.0.1:9669', 'username': 'root', 'password': 'nebula'}}, 'organization': 'iDC-NE', 'embedding': {'name': 'huggingface', 'model': 'BAAI/bge-large-en-v1.5', 'dim': 1024, 'device': 'cuda:1', 'batch_size': 48}, 'shouldRebuildDatabase': False, 'score_min': 20, 'score_max': 200, 'iteration': 0, 'use_local_model': True, 'entity': 10, 'hop': 2, 'pruning': 10, 'algorithm': 'basic_batch', 'batch_size': 4, 'redundancy': False, 'feedback': True, 'rate': 0.0, 'evolve_basic': {'graphrag_response': 'basic', 'extract_keywords': 'basic', 'retrieve_path': 'basic', 'simThreshold': 0.55, 'score_weight': 0.5, 'scoreThreshold': 70, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'basic_for_triplet', 'top_k_per_entity': True, 'lr': 5000000}, 'evolve_standard': {'graphrag_response': 'basic', 'extract_keywords': 'basic', 'retrieve_path': 'standard', 'simThreshold': 0, 'scoreThreshold': -2, 'score_weight': 0.5, 'lr': 5000000, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'standard_for_path', 'top_k_per_entity': True}, 'evolve_shared_prefix': {'graphrag_response': 'basic_shared_prefix', 'extract_keywords': 'basic', 'retrieve_path': 'standard', 'simThreshold': 0, 'score_weight': 0.5, 'scoreThreshold': -2, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'standard_for_path_shared_prefix', 'top_k_per_entity': True, 'lr': 5000000}, 'standard_batch': {'graphrag_response': 'basic_shared_prefix', 'extract_keywords': 'basic', 'retrieve_path': 'standard', 'simThreshold': 0, 'score_weight': 0.5, 'scoreThreshold': -2, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'standard_for_path_shared_prefix', 'top_k_per_entity': True, 'lr': 5000000}, 'basic_batch': {'graphrag_response': 'basic_shared_prefix', 'extract_keywords': 'basic', 'retrieve_path': 'basic', 'simThreshold': 0, 'score_weight': 0.5, 'scoreThreshold': 61, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'basic_for_triplet_shared_prefix', 'top_k_per_entity': True, 'lr': 5000000}, 'graphrag_response': 'basic_shared_prefix', 'extract_keywords': 'basic', 'retrieve_path': 'basic', 'simThreshold': 0, 'score_weight': 0.5, 'scoreThreshold': 61, 'redundant_process': 'basic_only_relationship_strict', 'feedback_process': 'basic_for_triplet_shared_prefix', 'top_k_per_entity': True, 'lr': 5000000, 'dataset_name': 'rgb', 'forward_llm': 'Meta-Llama-3-8B-Instruct', 'llm_fb': 'None', 'graphdb': 'nebulagraph', 'space_name': 'rgb_zyz', 'option': 'evolve_batch', 'llmbackend': 'llama_index', 'type': 'unchanged', 'similar': False}
All required directories are ready.
Use llama_index backend to generate
[1;3;33m
 test llm model llama3.1:8b-instruct-fp16 : I'm an artificial intelligence model known as Llama. Llama stands for "Large Language Model Meta AI."
[0mload embedding from /home/hdd/zhangyz/rag-data/rgb_zyz-triplet-embedding-standard.npz
Load embedding from /home/hdd/zhangyz/rag-data/rgb_zyz-entity-embedding-standard.npz
npz contain entity number '54544' with embedding number 54544.
Âä†ËΩΩÂ∑≤ÊúâÁºìÂ≠òÁ¥¢Âºï: /home/hdd/zhangyz/rag-data/rgb_zyz-path2id.json
Ê£ÄÊµãÂà∞Â∑≤ÊúâÂµåÂÖ•Êñá‰ª∂ÔºåÂÖ± 674310 Êù°„ÄÇ
-----------1‰∏™Ê®°Âûã------------------
evolve_basic iteration: 0 batch_size: 4
<class 'int'>
self.args.iteration: 0
Batch 0: start=0, end=4
EmbeddingEnv: embed_name BAAI/bge-large-en-v1.5, embed_batch_size 48, dim 1024, device cuda:1
use huggingface embedding BAAI/bge-large-en-v1.5
Processing index: 0
Processing index: 1
Processing index: 2
Processing index: 3
Batch 1: start=4, end=8
Processing index: 4
Processing index: 5
Processing index: 6
Processing index: 7
Batch 2: start=8, end=10
Processing index: 8
Processing index: 9
query_number: 10
